{"cells":[{"cell_type":"markdown","id":"25eecb55-8b2d-4afc-9a37-4447f1bf1922","metadata":{"id":"25eecb55-8b2d-4afc-9a37-4447f1bf1922"},"source":["# Collect and analyse YouTube data"]},{"cell_type":"markdown","id":"4e1295eb-09e9-4cf9-9c2f-43b34389c06b","metadata":{"id":"4e1295eb-09e9-4cf9-9c2f-43b34389c06b"},"source":["First, let's install a few relevant libraries:"]},{"cell_type":"code","execution_count":null,"id":"d1d3349f-249f-42b3-99bb-14553e52c052","metadata":{"id":"d1d3349f-249f-42b3-99bb-14553e52c052"},"outputs":[],"source":["!pip install jsonlines tqdm pandas google-api-python-client"]},{"cell_type":"markdown","id":"10906997-9a4e-4cbb-ae1b-97f085d4fd21","metadata":{"id":"10906997-9a4e-4cbb-ae1b-97f085d4fd21"},"source":["...and load these libraries"]},{"cell_type":"code","execution_count":null,"id":"c5bf525e-9bd9-40b1-8ed4-b2d679b6dfa0","metadata":{"id":"c5bf525e-9bd9-40b1-8ed4-b2d679b6dfa0"},"outputs":[],"source":["import os\n","os.getcwd() # This line of code returns my current working directory"]},{"cell_type":"code","execution_count":null,"id":"42a23705-0b00-4d31-bd66-0c77ee5491c0","metadata":{"id":"42a23705-0b00-4d31-bd66-0c77ee5491c0"},"outputs":[],"source":["import jsonlines\n","from tqdm import tqdm\n","import pandas as pd\n","\n","import googleapiclient.discovery\n","import googleapiclient.errors\n","from googleapiclient.discovery import build"]},{"cell_type":"markdown","id":"7c17611c-6ce2-43a0-8781-dbc174ab4952","metadata":{"id":"7c17611c-6ce2-43a0-8781-dbc174ab4952"},"source":[]},{"cell_type":"markdown","id":"6a9cdb74-fe3f-42a2-81e0-0140e070a08e","metadata":{"id":"6a9cdb74-fe3f-42a2-81e0-0140e070a08e"},"source":["## Obtaining credentials for the YouTube Data API"]},{"cell_type":"markdown","id":"3424ac64-02f4-4889-9b3d-ddd09b4b3191","metadata":{"id":"3424ac64-02f4-4889-9b3d-ddd09b4b3191"},"source":["Getting access to the YouTube Data API\n","\n","* **Step 1**: Go to the Google Cloud Console and login with a Google account: https://console.cloud.google.com/\n","\n","The next steps are clearly given in the following video (from 0:00 to 4:39): https://www.youtube.com/watch?v=th5_9woFJmk&ab_channel=CoreySchafer . We recommend watching this segment of the video and following the steps as you go, but just in case the following bullet points summarise the steps in writing:\n","\n","* **Step 2**: Once you are in the Google Cloud Console, create a new project by clicking the “Create Project” button, or by clicking the project dropdown menu at the top of the page and clicking the “New Project” button. The newly created project should be automatically selected as your current project but if this isn’t the case, simply select it in the list of projects in the project dropdown menu (at the top of the page).\n","\n","* **Step 3**: Use the search bar at the top of the page to search for “Youtube Data API v3” and click on the result when it appears (note that more than one result may appear, so select the option entitled “Youtube Data API v3”).\n","\n","* **Step 4**: Once on the page for “Youtube Data API v3”, click on the blue button that says “Enable”.\n","\n","* **Step 5**: At this point you should have been automatically directed to a page with “API services” written in the top-left corner. Once there, click on “Create credentials”.\n","\n","* **Step 6**: A form will appear. Under “Which API are you using?” Select “Youtube Data API v3”, and under “What data will you be accessing?” Select “Public data”.\n","\n","* **Step 7**: Once the form is submitted, the API key will be displayed. Copy this key and paste instead of \"YOUR_API_KEY\" in the api_key variable below.\n","\n","\n","**IMPORTANT**: For safety reasons we recommend that, once you are done collecting data for a project, you go back to your project in the Google Cloud Console and delete the API key.\n"]},{"cell_type":"code","execution_count":null,"id":"bc6d1d0c-e8a9-43c1-9f7f-10f9b2c01ea5","metadata":{"id":"bc6d1d0c-e8a9-43c1-9f7f-10f9b2c01ea5"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"4595b2d6-06ec-4ddb-b79b-6350a65e0397","metadata":{"id":"4595b2d6-06ec-4ddb-b79b-6350a65e0397"},"source":["## Initialising API client"]},{"cell_type":"code","execution_count":null,"id":"4868c8b1-b33e-4dad-b0ac-2f22164e3d3b","metadata":{"id":"4868c8b1-b33e-4dad-b0ac-2f22164e3d3b"},"outputs":[],"source":["# Disable OAuthlib's HTTPS verification when running locally.\n","os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n","\n","api_key = \"your-api-key\"  # Replace \"YOUR_API_KEY_HERE\" with your actual API key\n","api_service_name = \"youtube\"\n","api_version = \"v3\""]},{"cell_type":"code","execution_count":null,"id":"b08e92b2-7df4-43c8-9f20-b81ff8756907","metadata":{"id":"b08e92b2-7df4-43c8-9f20-b81ff8756907"},"outputs":[],"source":["youtube = build(api_service_name, api_version, developerKey=api_key)"]},{"cell_type":"code","execution_count":null,"id":"5137352f-5cb1-4d8c-a07b-8205b15d211e","metadata":{"id":"5137352f-5cb1-4d8c-a07b-8205b15d211e"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"6966abe5-eae3-4196-808e-a1e778a3b211","metadata":{"id":"6966abe5-eae3-4196-808e-a1e778a3b211"},"source":["## Designing the request you want to make using the API documentation"]},{"cell_type":"markdown","id":"0ae5a033-4d7a-44ab-9af4-414699865574","metadata":{"id":"0ae5a033-4d7a-44ab-9af4-414699865574"},"source":["The following webpages provide all the information you need to make requests using the YouTube API\n","\n","**YouTube Data API documentation**: https://developers.google.com/youtube/v3/docs\n","\n","**YouTube Data API requests pricing**: https://developers.google.com/youtube/v3/determine_quota_cost"]},{"cell_type":"code","execution_count":null,"id":"f588e8fe-c477-48e2-8c45-17431f0c3c14","metadata":{"id":"f588e8fe-c477-48e2-8c45-17431f0c3c14"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"3fba8b20-ad5e-4bc5-933a-193150bd4796","metadata":{"id":"3fba8b20-ad5e-4bc5-933a-193150bd4796"},"source":["## Collecting data"]},{"cell_type":"markdown","id":"c8524b13-6656-49da-abc8-235ad65095e2","metadata":{"id":"c8524b13-6656-49da-abc8-235ad65095e2"},"source":["### Searching for lists of videos from a keyword"]},{"cell_type":"markdown","id":"f8d19ea0-488c-4417-8cc7-ba2a4ab89209","metadata":{"id":"f8d19ea0-488c-4417-8cc7-ba2a4ab89209"},"source":["Let's query the YouTube Data API for the 50 most viewed videos published between the 11th and the 22nd of November 2024 (i.e. during COP29) relating to the keywords \"climate change\" or \"global warming\". We will further restrict the results to only retrieve videos (e.g. not playlists) and to have only English videos:"]},{"cell_type":"code","execution_count":null,"id":"504f8869-e7b0-45b7-b4a1-8d8a2f624cea","metadata":{"id":"504f8869-e7b0-45b7-b4a1-8d8a2f624cea"},"outputs":[],"source":["request = youtube.search().list(\n","    part=\"snippet\",\n","    maxResults=50,\n","    publishedAfter=\"2024-11-11T00:00:00Z\",\n","    publishedBefore=\"2024-11-22T00:00:00Z\",\n","    order=\"viewCount\",\n","    q=\"climate change | global warming\",\n","    relevanceLanguage=\"en\",\n","    type=\"video\"\n",")\n","response = request.execute()"]},{"cell_type":"markdown","id":"6aeceec5-f54b-4989-a2a4-9e6431038b78","metadata":{"id":"6aeceec5-f54b-4989-a2a4-9e6431038b78"},"source":["Let's look at the response we obtained..."]},{"cell_type":"code","execution_count":null,"id":"50365b44-0162-46a0-a1fc-cd3442d442c8","metadata":{"id":"50365b44-0162-46a0-a1fc-cd3442d442c8"},"outputs":[],"source":["response.keys()"]},{"cell_type":"code","execution_count":null,"id":"1e7891fe-88dd-4301-8ce4-f757c5ce1068","metadata":{"id":"1e7891fe-88dd-4301-8ce4-f757c5ce1068"},"outputs":[],"source":["len(response[\"items\"])"]},{"cell_type":"code","execution_count":null,"id":"1fd0fd66-7b99-4e45-957e-43cdfec02bf1","metadata":{"id":"1fd0fd66-7b99-4e45-957e-43cdfec02bf1"},"outputs":[],"source":["response[\"items\"][0]"]},{"cell_type":"code","execution_count":null,"id":"63493501-87d4-4964-a363-1daffdbd3874","metadata":{"id":"63493501-87d4-4964-a363-1daffdbd3874"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"d0cc1440-e6f8-42b5-b7f9-6dd17f626032","metadata":{"id":"d0cc1440-e6f8-42b5-b7f9-6dd17f626032"},"source":["The response contains a \"nextPageToken\" parameter:"]},{"cell_type":"code","execution_count":null,"id":"75ba37a3-d950-458f-a816-13e43d71cd24","metadata":{"id":"75ba37a3-d950-458f-a816-13e43d71cd24"},"outputs":[],"source":["response[\"nextPageToken\"]"]},{"cell_type":"markdown","id":"3a4fc0df-b04c-4617-a8a6-0286fb547e0c","metadata":{"id":"3a4fc0df-b04c-4617-a8a6-0286fb547e0c"},"source":["The \"nextPageToken\" can be used to obtain the next page of results:"]},{"cell_type":"code","execution_count":null,"id":"05b99576-eaff-487d-9f42-e73266b8bcfb","metadata":{"id":"05b99576-eaff-487d-9f42-e73266b8bcfb"},"outputs":[],"source":["request = youtube.search().list(\n","    part=\"snippet\",\n","    maxResults=50,\n","    publishedAfter=\"2024-11-11T00:00:00Z\",\n","    publishedBefore=\"2024-11-22T00:00:00Z\",\n","    order=\"viewCount\",\n","    q=\"climate change | global warming\",\n","    relevanceLanguage=\"en\",\n","    type=\"video\",\n","    pageToken=response[\"nextPageToken\"] # We added this argument here to specify we want the next page of results\n",")\n","next_page_response = request.execute()"]},{"cell_type":"code","execution_count":null,"id":"ff6dce7f-bddc-4626-9d8b-18210a008800","metadata":{"id":"ff6dce7f-bddc-4626-9d8b-18210a008800"},"outputs":[],"source":["len(next_page_response[\"items\"])"]},{"cell_type":"code","execution_count":null,"id":"5a4cbc06-114f-43e8-bde3-d46956fe8661","metadata":{"id":"5a4cbc06-114f-43e8-bde3-d46956fe8661"},"outputs":[],"source":["next_page_response[\"items\"][0]"]},{"cell_type":"code","execution_count":null,"id":"6a6af466-6b20-4bdd-abe0-86cd91e6b338","metadata":{"id":"6a6af466-6b20-4bdd-abe0-86cd91e6b338"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"bd14220d-3a9b-4413-926e-09f0d2344bed","metadata":{"id":"bd14220d-3a9b-4413-926e-09f0d2344bed"},"source":["Let's generalise the previous code so that we collect the N first pages of results for our query:"]},{"cell_type":"code","execution_count":null,"id":"27bce1b0-6220-4a8a-a8ce-92ab293307a8","metadata":{"id":"27bce1b0-6220-4a8a-a8ce-92ab293307a8"},"outputs":[],"source":["N = 2                      # We set N to 2 to define that we want the top 2 pages of results only. We can change the value of N if we want a different number of pages.\n","next_page_token = None     # The next_page_token variable will be used in the for loop to store the ID of the next page. We set it to None for the initial query.\n","search_results = list()    # We create an empty list to store the comment query results\n","\n","# Let's iterate over the number of pages we want...\n","for i in tqdm(range(N)): # The \"tqdm\" wrapper around the \"ids_list\" variable allows us to see a progress bar\n","\n","    # Retrieve a page of results for search query\n","    if next_page_token is None:\n","        # If \"next_page_token\" is  None (i.e. if this is the request for the first page), we do not use \"pageToken\" as a query parameter...\n","        request = youtube.search().list(\n","            part=\"snippet\",\n","            maxResults=50,\n","            publishedAfter=\"2024-11-11T00:00:00Z\",\n","            publishedBefore=\"2024-11-22T00:00:00Z\",\n","            order=\"viewCount\",\n","            q=\"climate change | global warming\",\n","            relevanceLanguage=\"en\",\n","            type=\"video\"\n","        )\n","        page_response = request.execute()\n","        search_results.append(page_response)\n","    else:\n","        # If it not None however, we use \"nextPageToken\" to specify the \"pageToken\" as a query parameter...\n","        request = youtube.search().list(\n","            part=\"snippet\",\n","            maxResults=50,\n","            publishedAfter=\"2024-11-11T00:00:00Z\",\n","            publishedBefore=\"2024-11-22T00:00:00Z\",\n","            order=\"viewCount\",\n","            q=\"climate change | global warming\",\n","            relevanceLanguage=\"en\",\n","            type=\"video\",\n","            pageToken=next_page_token\n","        )\n","        page_response = request.execute()\n","        search_results.append(page_response)\n","\n","    # Try to retrieve the \"nextPageToken\" if there is one.\n","    try:\n","        next_page_token = page_response[\"nextPageToken\"]\n","\n","    # If the response does not have a \"nextPageToken\" field, we simply break out of the loop\n","    except KeyError:\n","        break"]},{"cell_type":"code","execution_count":null,"id":"d413c39e-c9b6-47c1-abbc-640149fca3b6","metadata":{"id":"d413c39e-c9b6-47c1-abbc-640149fca3b6"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"8b9f9e9b-0135-4c06-bd27-ad55c29c16af","metadata":{"id":"8b9f9e9b-0135-4c06-bd27-ad55c29c16af"},"source":["### Retrieving comment threads from videos"]},{"cell_type":"markdown","id":"ad230082-0f90-471e-99ee-971e739c2159","metadata":{"id":"ad230082-0f90-471e-99ee-971e739c2159"},"source":["Let's test the comment query for just one video. Here, we will use of the very first video returned by the search query:"]},{"cell_type":"code","execution_count":null,"id":"f860ac2f-5413-4439-afa0-93cf82f05d0e","metadata":{"id":"f860ac2f-5413-4439-afa0-93cf82f05d0e"},"outputs":[],"source":["video_id = search_results[0][\"items\"][0][\"id\"][\"videoId\"]\n","video_id"]},{"cell_type":"code","execution_count":null,"id":"a3d0078f-4e92-4fee-b79f-6d319ed28640","metadata":{"id":"a3d0078f-4e92-4fee-b79f-6d319ed28640"},"outputs":[],"source":["request = youtube.commentThreads().list(\n","    part=\"snippet,id,replies\",\n","    maxResults=100,\n","    order=\"time\",\n","    videoId=video_id\n",")\n","comment_response = request.execute()"]},{"cell_type":"markdown","id":"5912ac71-ddb1-4a5b-a4d6-ea28f8036c91","metadata":{"id":"5912ac71-ddb1-4a5b-a4d6-ea28f8036c91"},"source":["The response to this query contains the following keys:"]},{"cell_type":"code","execution_count":null,"id":"8f9b43ae-1c7d-4a88-b8bd-124476e185d5","metadata":{"id":"8f9b43ae-1c7d-4a88-b8bd-124476e185d5"},"outputs":[],"source":["comment_response.keys()"]},{"cell_type":"markdown","id":"ba2386fc-14ec-42d8-b76b-f9f72d9c9db2","metadata":{"id":"ba2386fc-14ec-42d8-b76b-f9f72d9c9db2"},"source":["The response does not contain a \"nextPageToken\" field, which means that the video contains less than 100 comment threads. We can verify this by looking at the number of threads in the response:"]},{"cell_type":"code","execution_count":null,"id":"c470fef7-0b4f-40f4-aa80-fa259b97899c","metadata":{"id":"c470fef7-0b4f-40f4-aa80-fa259b97899c"},"outputs":[],"source":["len(comment_response[\"items\"][0])"]},{"cell_type":"code","execution_count":null,"id":"c7a5569b-768b-4090-b557-93570bf179b1","metadata":{"id":"c7a5569b-768b-4090-b557-93570bf179b1"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"89b97643-0567-453b-8d20-8449567124df","metadata":{"id":"89b97643-0567-453b-8d20-8449567124df"},"source":["Having tested the comment collection query for a single video, let's create a for loop to collect the comments for all the videos in the search queries stored in the \"search_results\" variables. To do this, we first need to retrieve all the video IDs from the results in \"search_results\":"]},{"cell_type":"code","execution_count":null,"id":"506f27bb-00b6-4011-b41c-d16a11584788","metadata":{"id":"506f27bb-00b6-4011-b41c-d16a11584788"},"outputs":[],"source":["ids_list = list()\n","\n","for result in search_results:\n","    for item in result[\"items\"]:\n","        ids_list.append(item[\"id\"][\"videoId\"])"]},{"cell_type":"code","execution_count":null,"id":"6a081545-f54b-4804-8fbe-c83df0946e83","metadata":{"id":"6a081545-f54b-4804-8fbe-c83df0946e83"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"2a0fd3bb-23a1-4624-87a1-5d75670ced08","metadata":{"id":"2a0fd3bb-23a1-4624-87a1-5d75670ced08"},"source":["Having retrieved the video IDs, we can now run the for loop to query the YouTube for comments. The for loop should be able to handle cases where a video has more than one page of comments (i.e. more than 100 comment threads):"]},{"cell_type":"code","execution_count":null,"id":"f35fa314-5540-4452-bab3-c9ff9ea472a1","metadata":{"id":"f35fa314-5540-4452-bab3-c9ff9ea472a1"},"outputs":[],"source":["comment_results = dict() # We create an empty dictionary to store the comment query results\n","\n","# Let's iterate over the video IDs...\n","for id in tqdm(ids_list[:3]):\n","\n","    # We initialise the comment results for this particular video ID to be an empty list\n","    comment_results[id] = list()\n","\n","    # Try to retrieve the first page of comments for the video\n","    try:\n","        request = youtube.commentThreads().list(\n","            part=\"snippet,id,replies\",\n","            maxResults=100,\n","            order=\"time\",\n","            videoId=id\n","        )\n","        comment_response = request.execute()\n","        comment_results[id].append(comment_response)\n","\n","    # Some video might have disable comments. If this is the case, these lines of code will catch the error and simply move on to the next video.\n","    except Exception as e:\n","        print(id, e)\n","        continue  # The \"continue\" command will skip the rest of the code in this iteration of the loop\n","\n","    # Try to retrieve the \"nextPageToken\" if there is one.\n","    try:\n","        nextPageToken = comment_response[\"nextPageToken\"]\n","\n","    # If the response does not have a \"nextPageToken\" field, the loop simply moves on to the next video\n","    except KeyError:\n","        continue\n","\n","    # Given that a value was found for \"nextPageToken\", let's retrieve the comments of the next page until a \"nextPageToken\" cannot be found\n","    while True:\n","        request = youtube.commentThreads().list(\n","            part=\"snippet,id,replies\",\n","            maxResults=100,\n","            order=\"time\",\n","            videoId=id,\n","            pageToken=nextPageToken\n","        )\n","        comment_response = request.execute()\n","        comment_results[id].append(comment_response)\n","        try:\n","            nextPageToken = comment_response[\"nextPageToken\"]\n","        except KeyError:\n","            break"]},{"cell_type":"code","execution_count":null,"id":"2435a258-5a51-4433-bb5d-9f4fe114b025","metadata":{"id":"2435a258-5a51-4433-bb5d-9f4fe114b025"},"outputs":[],"source":["comment_results.keys()"]},{"cell_type":"code","execution_count":null,"id":"fc0b2719-858b-4a3b-a232-55d8883da4e1","metadata":{"id":"fc0b2719-858b-4a3b-a232-55d8883da4e1"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"2014def7-8576-47eb-a311-01cf57f98c36","metadata":{"id":"2014def7-8576-47eb-a311-01cf57f98c36"},"source":["## Calculate simple statistics to identify interesting video"]},{"cell_type":"markdown","id":"fb9a43be-1cfe-488e-995c-afe8aca957e4","metadata":{"id":"fb9a43be-1cfe-488e-995c-afe8aca957e4"},"source":["Let's compute for each video its number of comment threads, its total number of comments and the number of comments per thread:"]},{"cell_type":"code","execution_count":null,"id":"8dc5b0ad-06ca-45d6-bfd6-7dfe080df4f5","metadata":{"id":"8dc5b0ad-06ca-45d6-bfd6-7dfe080df4f5"},"outputs":[],"source":["stats_list = list()\n","\n","for i, id in enumerate(comment_results):\n","    nb_threads = 0\n","    nb_comments = 0\n","    nb_comments_per_thread = None\n","\n","    for result in comment_results[id]:\n","        nb_threads += len(result[\"items\"])\n","        for item in result[\"items\"]:\n","            nb_comments += 1\n","            if \"replies\" in item:\n","                nb_comments += len(item[\"replies\"][\"comments\"])\n","\n","    if nb_threads > 0:\n","        nb_comments_per_thread = (nb_comments/nb_threads)\n","\n","    stats_list.append({\"video_id\": id, \"nb_threads\": nb_threads, \"nb_comments\": nb_comments, \"nb_comments_per_thread\": nb_comments_per_thread})\n","\n","stats_df = pd.DataFrame(stats_list)\n","stats_df"]},{"cell_type":"code","execution_count":null,"id":"0b1cd0fe-0e2c-40e1-9286-1c5d425b9ba3","metadata":{"id":"0b1cd0fe-0e2c-40e1-9286-1c5d425b9ba3"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"f7e6da90-3b1c-4d4c-9551-8525399e9751","metadata":{"id":"f7e6da90-3b1c-4d4c-9551-8525399e9751"},"source":["Let's sort the results by the number of comments:"]},{"cell_type":"code","execution_count":null,"id":"998ade6a-4b3e-4feb-b46b-a638582ac8b5","metadata":{"id":"998ade6a-4b3e-4feb-b46b-a638582ac8b5"},"outputs":[],"source":["stats_df.sort_values(by=['nb_comments'], ascending=False)"]},{"cell_type":"code","execution_count":null,"id":"e432798c-66f8-4357-94a6-b34fb0742886","metadata":{"id":"e432798c-66f8-4357-94a6-b34fb0742886"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"08c34d7e-65b2-4de7-9980-04eaca6f9039","metadata":{"id":"08c34d7e-65b2-4de7-9980-04eaca6f9039"},"source":["For the rest of this analysis, we'll simply focus on the video with the most comments:"]},{"cell_type":"code","execution_count":null,"id":"38363725-5a9f-4c47-8e20-31a79cb2e65e","metadata":{"id":"38363725-5a9f-4c47-8e20-31a79cb2e65e"},"outputs":[],"source":["rel_ID = stats_df.sort_values(by=['nb_comments'], ascending=False).iloc[0][\"video_id\"]\n","rel_ID"]},{"cell_type":"markdown","id":"86d1f448-5eec-4c6a-9550-e013bc9e6cc8","metadata":{"id":"86d1f448-5eec-4c6a-9550-e013bc9e6cc8"},"source":["We can select the value in the \"comment_results\" dictionary (which holds all comments per video) for the video with the specified ID:"]},{"cell_type":"code","execution_count":null,"id":"d232abf4-48e7-4e49-88c2-85ac7e31e566","metadata":{"id":"d232abf4-48e7-4e49-88c2-85ac7e31e566"},"outputs":[],"source":["rel_comment_results = comment_results[rel_ID]"]},{"cell_type":"markdown","id":"7dcca5bd-7cb6-4a0b-ab4f-783ebee8e128","metadata":{"id":"7dcca5bd-7cb6-4a0b-ab4f-783ebee8e128"},"source":["We will use this data in the next section to generate a social network visualisation."]},{"cell_type":"code","execution_count":null,"id":"c8ca8424-20b7-4c23-969c-10319e0bfe51","metadata":{"id":"c8ca8424-20b7-4c23-969c-10319e0bfe51"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"31f4f9d9-3003-40f6-9ab5-07216bbb88e1","metadata":{"id":"31f4f9d9-3003-40f6-9ab5-07216bbb88e1"},"source":["## Social Network Analysis"]},{"cell_type":"markdown","id":"d34e6d47-3a36-4592-b076-8ea5da4b8a04","metadata":{"id":"d34e6d47-3a36-4592-b076-8ea5da4b8a04"},"source":["We will use a version of the \"comment_list_to_edge_list\" function from the Reddit Notebook adapted to the format of data returned by the YouTube API to generate a Gephi CSV edge list:"]},{"cell_type":"code","execution_count":null,"id":"9d35d754-d893-4d9f-b18b-54fd8abd2abe","metadata":{"id":"9d35d754-d893-4d9f-b18b-54fd8abd2abe"},"outputs":[],"source":["def comment_list_to_edge_list(comments, include_parent = False):\n","    \"\"\"\n","    A function that converts the comments on a YouTube video into a Gephi CSV edge list.\n","\n","    The input list is expected to be a list for which each item is a response from the YouTube Data API for a comment thread query. Each item corresponds to a different page of results for the same video.\n","\n","    The DataFrame returned is in a format so it can be written to a CSV edge list using Pandas' to_csv method.\n","\n","    The edge list will include an edge from the author of a reply to the author of the comment that is being\n","    replied to.\n","\n","    If you pass the optional parameter include_parent, the edge list will also include edges from the authors of\n","    top-level comments to the author of the video. In that case include_parent should be set to the\n","    user name of the youtuber who published the video.\n","    \"\"\"\n","\n","    user_pairs = list()\n","\n","    # Let's iterate over the pages of results\n","    for page in comments:\n","\n","        # Let's iterate over the comment threads in each page\n","        for thread in page[\"items\"]:\n","\n","            # Retrieve the name of the author of the top level comment in the presen thread\n","            top_comment_author = thread[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"authorDisplayName\"]\n","\n","            # If include_parent is not False, add an edge between the video author and the top level comment author\n","            if include_parent is not False:\n","                user_pairs.append({\"author_parent\": include_parent, \"author_child\": top_comment_author})\n","\n","            # If the top level comment has replies, let's add an edge between each replier and the author of the top level comment\n","            if \"replies\" in thread:\n","                for comment in thread[\"replies\"][\"comments\"]:\n","                    user_pairs.append({\"author_parent\": top_comment_author, \"author_child\": comment[\"snippet\"][\"authorDisplayName\"]})\n","\n","    # Conver the list of edges to a pandas DataFrame, so we can use Pandas' to_csv method later to save the list of edges\n","    edgelist = pd.DataFrame(user_pairs)\n","\n","    return edgelist"]},{"cell_type":"code","execution_count":null,"id":"e16d2a2e-6b8b-41b0-a411-d228c0a644d3","metadata":{"id":"e16d2a2e-6b8b-41b0-a411-d228c0a644d3"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"2c206658-340d-45be-b347-c13af2bef5ed","metadata":{"id":"2c206658-340d-45be-b347-c13af2bef5ed"},"source":["We want to include top level comments as replies to the video's author in our social network analysis. We therefore need the author name for the chosen video:"]},{"cell_type":"code","execution_count":null,"id":"96845e87-89a0-43c8-947b-deb2af411aa8","metadata":{"id":"96845e87-89a0-43c8-947b-deb2af411aa8"},"outputs":[],"source":["for result in search_results:\n","    for video in result[\"items\"]:\n","        if video[\"id\"][\"videoId\"] == rel_ID:\n","            video_author = video[\"snippet\"][\"channelTitle\"]"]},{"cell_type":"markdown","id":"9bdf1948-e8f9-4249-a0df-29eb47ff136f","metadata":{"id":"9bdf1948-e8f9-4249-a0df-29eb47ff136f"},"source":["We can then generate the list of edges and save it as a file:"]},{"cell_type":"code","execution_count":null,"id":"d11d51a7-37ea-4285-bb10-0a81d8962500","metadata":{"id":"d11d51a7-37ea-4285-bb10-0a81d8962500"},"outputs":[],"source":["edgelist = comment_list_to_edge_list(rel_comment_results, video_author)"]},{"cell_type":"code","execution_count":null,"id":"58db3ea7-02ac-42f5-8e6a-30e7e0e8bf72","metadata":{"id":"58db3ea7-02ac-42f5-8e6a-30e7e0e8bf72"},"outputs":[],"source":["edgelist"]},{"cell_type":"code","execution_count":null,"id":"8e3eeda1-6207-4f64-895e-8aa677541e82","metadata":{"id":"8e3eeda1-6207-4f64-895e-8aa677541e82"},"outputs":[],"source":["edgelist.to_csv('comments_' + rel_ID + '.csv', index = False)"]},{"cell_type":"code","execution_count":null,"id":"dcf1665f-cd5e-4b9d-b77d-190294de7d63","metadata":{"id":"dcf1665f-cd5e-4b9d-b77d-190294de7d63"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"7751dfb1-8672-433b-b5fd-fa8a71849c2e","metadata":{"id":"7751dfb1-8672-433b-b5fd-fa8a71849c2e"},"source":["## Save your results"]},{"cell_type":"code","execution_count":null,"id":"50f07f0f-0e9d-4f9d-a75e-18b9195510f8","metadata":{"id":"50f07f0f-0e9d-4f9d-a75e-18b9195510f8"},"outputs":[],"source":["with jsonlines.open(\"./search_results.jsonl\", mode=\"w\") as writer:\n","    for obj in search_results:\n","        writer.write(obj)"]},{"cell_type":"code","execution_count":null,"id":"0858fa8a-aa24-4311-aa20-4a934a714092","metadata":{"id":"0858fa8a-aa24-4311-aa20-4a934a714092"},"outputs":[],"source":["with jsonlines.open(\"./comment_results.jsonl\", mode=\"w\") as writer:\n","    for obj in [comment_results]:\n","        writer.write(obj)"]},{"cell_type":"code","execution_count":null,"id":"39f6bed8-ca69-4e49-a295-7c3d50a90ccc","metadata":{"id":"39f6bed8-ca69-4e49-a295-7c3d50a90ccc"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"34f53c29-1644-4f94-b5ea-60c07431bd44","metadata":{"id":"34f53c29-1644-4f94-b5ea-60c07431bd44"},"source":["If you want to read the results from memory, here is how to do it:"]},{"cell_type":"code","execution_count":null,"id":"6d417623-18b9-43f4-babe-8669ee7c6e39","metadata":{"id":"6d417623-18b9-43f4-babe-8669ee7c6e39"},"outputs":[],"source":["search_results = list()\n","with jsonlines.open(\"./search_results.jsonl\", mode=\"r\") as reader:\n","    for obj in reader:\n","        search_results.append(obj)"]},{"cell_type":"code","execution_count":null,"id":"c4897c20-d62b-4e0b-84c0-6d1b157d140c","metadata":{"id":"c4897c20-d62b-4e0b-84c0-6d1b157d140c"},"outputs":[],"source":["comment_results = list()\n","with jsonlines.open(\"./comment_results.jsonl\", mode=\"r\") as reader:\n","    for obj in reader:\n","        comment_results.append(obj)\n","\n","comment_results = comment_results[0]"]},{"cell_type":"code","execution_count":null,"id":"0ac0fd8b-18ca-4b2b-8c91-7f1dbd6760ab","metadata":{"id":"0ac0fd8b-18ca-4b2b-8c91-7f1dbd6760ab"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}